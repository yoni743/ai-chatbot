{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Chatbot Training Visualization\n",
        "\n",
        "This notebook provides an interactive way to visualize the training process of the AI Chatbot, including:\n",
        "\n",
        "- Data exploration and preprocessing\n",
        "- Model architecture visualization\n",
        "- Training progress monitoring\n",
        "- Performance metrics analysis\n",
        "- Interactive testing of the trained model\n",
        "\n",
        "## Table of Contents\n",
        "1. [Setup and Imports](#setup)\n",
        "2. [Data Exploration](#data-exploration)\n",
        "3. [Model Training](#model-training)\n",
        "4. [Training Visualization](#training-visualization)\n",
        "5. [Model Testing](#model-testing)\n",
        "6. [Performance Analysis](#performance-analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports {#setup}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Add the src directory to the path\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Import our custom utilities\n",
        "from nltk_utils import load_intents, preprocess_data, create_training_data\n",
        "from train import create_model, train_model, plot_training_history, evaluate_model\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure TensorFlow for better performance\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Python version: {sys.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Exploration {#data-exploration}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and explore the intents data\n",
        "intents_data = load_intents('../data/intents.json')\n",
        "\n",
        "if intents_data:\n",
        "    print(\"üìä Intents Data Overview:\")\n",
        "    print(f\"Number of intents: {len(intents_data['intents'])}\")\n",
        "    \n",
        "    # Create a summary DataFrame\n",
        "    intent_summary = []\n",
        "    for intent in intents_data['intents']:\n",
        "        intent_summary.append({\n",
        "            'Intent': intent['tag'],\n",
        "            'Patterns': len(intent['patterns']),\n",
        "            'Responses': len(intent['responses']),\n",
        "            'Sample Pattern': intent['patterns'][0] if intent['patterns'] else '',\n",
        "            'Sample Response': intent['responses'][0] if intent['responses'] else ''\n",
        "        })\n",
        "    \n",
        "    df_intents = pd.DataFrame(intent_summary)\n",
        "    print(\"\\nüìã Intent Summary:\")\n",
        "    display(df_intents)\n",
        "    \n",
        "    # Visualize intent distribution\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Patterns per intent\n",
        "    ax1.bar(df_intents['Intent'], df_intents['Patterns'], color='skyblue', alpha=0.7)\n",
        "    ax1.set_title('Number of Patterns per Intent', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Intent')\n",
        "    ax1.set_ylabel('Number of Patterns')\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Responses per intent\n",
        "    ax2.bar(df_intents['Intent'], df_intents['Responses'], color='lightcoral', alpha=0.7)\n",
        "    ax2.set_title('Number of Responses per Intent', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Intent')\n",
        "    ax2.set_ylabel('Number of Responses')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print total statistics\n",
        "    total_patterns = df_intents['Patterns'].sum()\n",
        "    total_responses = df_intents['Responses'].sum()\n",
        "    print(f\"\\nüìà Total Statistics:\")\n",
        "    print(f\"Total patterns: {total_patterns}\")\n",
        "    print(f\"Total responses: {total_responses}\")\n",
        "    print(f\"Average patterns per intent: {total_patterns / len(intents_data['intents']):.1f}\")\n",
        "    print(f\"Average responses per intent: {total_responses / len(intents_data['intents']):.1f}\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to load intents data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess the data and explore vocabulary\n",
        "print(\"üîß Preprocessing data...\")\n",
        "words, labels, xy = preprocess_data(intents_data)\n",
        "\n",
        "# Create training data\n",
        "print(\"üìä Creating training data...\")\n",
        "X, y = create_training_data(words, labels, xy)\n",
        "\n",
        "print(f\"\\nüìà Data Statistics:\")\n",
        "print(f\"Vocabulary size: {len(words)}\")\n",
        "print(f\"Number of labels: {len(labels)}\")\n",
        "print(f\"Total training samples: {X.shape[0]}\")\n",
        "print(f\"Feature vector size: {X.shape[1]}\")\n",
        "\n",
        "# Visualize vocabulary distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Word length distribution\n",
        "word_lengths = [len(word) for word in words]\n",
        "ax1.hist(word_lengths, bins=20, color='skyblue', alpha=0.7, edgecolor='black')\n",
        "ax1.set_title('Distribution of Word Lengths in Vocabulary', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Word Length')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Label distribution\n",
        "label_counts = np.bincount(y)\n",
        "ax2.bar(labels, label_counts, color='lightcoral', alpha=0.7)\n",
        "ax2.set_title('Distribution of Training Samples per Intent', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Intent')\n",
        "ax2.set_ylabel('Number of Samples')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show sample of vocabulary\n",
        "print(f\"\\nüìù Sample Vocabulary (first 20 words):\")\n",
        "print(words[:20])\n",
        "\n",
        "# Show label distribution\n",
        "print(f\"\\nüè∑Ô∏è  Label Distribution:\")\n",
        "for i, label in enumerate(labels):\n",
        "    count = np.sum(y == i)\n",
        "    print(f\"  {label}: {count} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training {#model-training}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"üìä Data Split:\")\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Create the model\n",
        "print(f\"\\nüß† Creating neural network model...\")\n",
        "model = create_model(X_train.shape[1], len(labels))\n",
        "\n",
        "# Display model architecture\n",
        "print(f\"\\nüìã Model Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Visualize model architecture\n",
        "keras.utils.plot_model(model, to_file='../models/model_architecture.png', \n",
        "                      show_shapes=True, show_layer_names=True, rankdir='TB')\n",
        "print(\"‚úÖ Model architecture saved to models/model_architecture.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"üöÄ Starting model training...\")\n",
        "history = train_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=32)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('../models/chatbot_model.h5')\n",
        "print(\"‚úÖ Model saved to models/chatbot_model.h5\")\n",
        "\n",
        "# Save words and labels\n",
        "import pickle\n",
        "with open('../models/words.pkl', 'wb') as f:\n",
        "    pickle.dump(words, f)\n",
        "with open('../models/labels.pkl', 'wb') as f:\n",
        "    pickle.dump(labels, f)\n",
        "print(\"‚úÖ Vocabulary data saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Visualization {#training-visualization}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive training visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Training and validation accuracy\n",
        "axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2)\n",
        "axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)\n",
        "axes[0, 0].set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Training and validation loss\n",
        "axes[0, 1].plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n",
        "axes[0, 1].plot(history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)\n",
        "axes[0, 1].set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate (if available)\n",
        "if 'lr' in history.history:\n",
        "    axes[1, 0].plot(history.history['lr'], color='green', linewidth=2)\n",
        "    axes[1, 0].set_title('Learning Rate Over Time', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Learning Rate')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "else:\n",
        "    axes[1, 0].text(0.5, 0.5, 'Learning Rate Not Available', \n",
        "                    ha='center', va='center', transform=axes[1, 0].transAxes)\n",
        "    axes[1, 0].set_title('Learning Rate Over Time', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Final metrics comparison\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "metrics = ['Training', 'Validation']\n",
        "accuracies = [final_train_acc, final_val_acc]\n",
        "losses = [final_train_loss, final_val_loss]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "axes[1, 1].bar(x - width/2, accuracies, width, label='Accuracy', color='skyblue', alpha=0.7)\n",
        "axes[1, 1].bar(x + width/2, losses, width, label='Loss', color='lightcoral', alpha=0.7)\n",
        "axes[1, 1].set_title('Final Training vs Validation Metrics', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Dataset')\n",
        "axes[1, 1].set_ylabel('Value')\n",
        "axes[1, 1].set_xticks(x)\n",
        "axes[1, 1].set_xticklabels(metrics)\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print training summary\n",
        "print(\"üìä Training Summary:\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Total Epochs: {len(history.history['accuracy'])}\")\n",
        "\n",
        "# Check for overfitting\n",
        "if final_val_acc < final_train_acc - 0.1:\n",
        "    print(\"‚ö†Ô∏è  Warning: Potential overfitting detected (validation accuracy significantly lower than training)\")\n",
        "elif final_val_acc > final_train_acc:\n",
        "    print(\"‚úÖ Good generalization: Validation accuracy is higher than training accuracy\")\n",
        "else:\n",
        "    print(\"‚úÖ Balanced training: Training and validation metrics are close\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Testing {#model-testing}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the model on test data\n",
        "print(\"üß™ Testing model on test data...\")\n",
        "\n",
        "# Get predictions\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = np.mean(predicted_classes == y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, predicted_classes, target_names=labels))\n",
        "\n",
        "# Test with sample inputs\n",
        "print(\"\\nü§ñ Interactive Testing:\")\n",
        "test_messages = [\n",
        "    \"Hello!\",\n",
        "    \"How are you?\",\n",
        "    \"What's your name?\",\n",
        "    \"Thank you very much\",\n",
        "    \"Goodbye!\",\n",
        "    \"Can you help me?\",\n",
        "    \"What's the weather like?\",\n",
        "    \"I don't understand this at all\"\n",
        "]\n",
        "\n",
        "for message in test_messages:\n",
        "    # This would require importing the chatbot class\n",
        "    # For now, we'll just show the message\n",
        "    print(f\"Test message: '{message}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
